"""
é”™è¯¯åˆ†æå™¨æ¨¡å—

ä¸“é—¨è´Ÿè´£é”™è¯¯æ ¹å› åˆ†æçš„é€»è¾‘ï¼ŒåŒ…æ‹¬é”™è¯¯æ¨¡å¼è¯†åˆ«å’Œæ ¹å› å®šä½ã€‚
"""

import logging
from datetime import datetime
from typing import List, Optional

from config import config_manager
from sls_client_manager import sls_client_manager, SLSClientError
from credential_manager import CredentialError
from .span_finders.error_span_finder import FindRootCauseSpans
from .shared_models import AnalysisResult

# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)


class ErrorAnalyzer:
    """é”™è¯¯åˆ†æå™¨"""

    def __init__(self):
        self.config = config_manager.get_analysis_config()
        self.sls_config = config_manager.get_sls_config()

    def analyze_error_root_cause(
        self, start_time: str, end_time: str, candidate_root_causes: List[str]
    ) -> AnalysisResult:
        """
        åˆ†æé”™è¯¯æ ¹å› 

        Args:
            start_time: å¼€å§‹æ—¶é—´ (YYYY-MM-DD HH:MM:SS)
            end_time: ç»“æŸæ—¶é—´ (YYYY-MM-DD HH:MM:SS)
            candidate_root_causes: å€™é€‰æ ¹å› åˆ—è¡¨

        Returns:
            AnalysisResult: åˆ†æç»“æœ
        """
        try:
            logger.info("--- å¼€å§‹æ‰§è¡Œé”™è¯¯æ ¹å› åˆ†æ ---")

            # 1. åˆ›å»ºSLSå®¢æˆ·ç«¯
            sls_client = sls_client_manager.get_client()

            # 2. åˆ›å»ºæ ¹å› spanæŸ¥æ‰¾å™¨
            root_cause_finder = FindRootCauseSpans(
                client=sls_client,
                project_name=self.sls_config.project_name,
                logstore_name=self.sls_config.logstore_name,
                region=self.sls_config.region,
                start_time=start_time,
                end_time=end_time,
            )

            # 3. æŸ¥æ‰¾æ ¹å› spans
            logger.info("å¼€å§‹æŸ¥æ‰¾æ ¹å› spans...")
            root_cause_span_ids = root_cause_finder.find_root_cause_spans()

            if not root_cause_span_ids:
                logger.warning("æœªæ‰¾åˆ°æ ¹å› span")
                return AnalysisResult(
                    root_causes=[],
                    confidence="low",
                    evidence=False,
                    error_message="No root cause spans found",
                )

            logger.info("æ‰¾åˆ° %d ä¸ªæ ¹å› span", len(root_cause_span_ids))

            # 4. æ‰§è¡Œæ¨¡å¼åˆ†æ
            pattern_result = self._analyze_error_patterns(
                start_time, end_time, root_cause_span_ids, candidate_root_causes
            )

            if pattern_result:
                return AnalysisResult(
                    root_causes=[pattern_result], confidence="high", evidence=True
                )

            return AnalysisResult(
                root_causes=[],
                confidence="low",
                evidence=False,
                error_message="No pattern analysis result found",
            )

        except (SLSClientError, CredentialError) as e:
            return AnalysisResult(
                root_causes=[],
                confidence="low",
                evidence=False,
                error_message=f"Client error: {e}",
            )
        except (ValueError, TypeError, RuntimeError) as e:
            return AnalysisResult(
                root_causes=[],
                confidence="low",
                evidence=False,
                error_message=f"Analysis error: {e}",
            )

    def _analyze_error_patterns(
        self, start_time: str, end_time: str, span_ids: List[str], candidates: List[str]
    ) -> Optional[str]:
        """åˆ†æé”™è¯¯æ¨¡å¼ - ä¸STS_Root_Cause_Analysis_Error.pyä¿æŒä¸€è‡´"""
        if not span_ids:
            return None

        try:
            # æ„å»ºspanæŸ¥è¯¢æ¡ä»¶
            span_conditions = " or ".join(
                [f"spanId='{span_id}'" for span_id in span_ids[:2000]]
            )

            # 1. æ‰§è¡Œget_patternsæŸ¥è¯¢
            get_patterns_result = self._execute_get_patterns_query(
                start_time, end_time, span_conditions
            )

            # 2. æ‰§è¡Œdiff_patternsæŸ¥è¯¢
            diff_patterns_result = self._execute_diff_patterns_query(
                start_time, end_time, span_conditions
            )

            # 3. è§£ææœåŠ¡è¯æ®ï¼ˆä¸STS_Root_Cause_Analysis_Error.pyé€»è¾‘ä¸€è‡´ï¼‰
            target_service = self._parse_service_from_evidence(
                get_patterns_result, diff_patterns_result, candidates
            )

            if target_service and target_service != "unknown":
                return f"{target_service}.Failure"

            return None

        except (ValueError, KeyError, TypeError) as e:
            logger.error("é”™è¯¯æ¨¡å¼åˆ†æå¤±è´¥: %s", e)
            return None

    def _execute_get_patterns_query(
        self, start_time: str, end_time: str, span_conditions: str
    ) -> Optional[any]:
        """æ‰§è¡Œget_patternsæŸ¥è¯¢"""
        pattern_query = f"""
* | set session enable_remote_functions=true ;
set session velox_support_row_constructor_enabled=true;
with t0 as (
    select spanName, serviceName,
           JSON_EXTRACT_SCALAR(resources, '$["k8s.pod.ip"]') AS pod_ip,
           JSON_EXTRACT_SCALAR(resources, '$["k8s.node.name"]') AS node_name,
           JSON_EXTRACT_SCALAR(resources, '$["service.version"]') AS service_version,
           if((statusCode = 2 or statusCode = 3), 'true', 'false') as anomaly_label,
           cast(if((statusCode = 2 or statusCode = 3), 1, 0) as double) as error_count
    from log
    where {span_conditions}
),
t1 as (
    select array_agg(spanName) as spanName,
           array_agg(serviceName) as serviceName,
           array_agg(pod_ip) as pod_ip,
           array_agg(node_name) as node_name,
           array_agg(service_version) as service_version,
           array_agg(anomaly_label) as anomaly_label,
           array_agg(error_count) as error_count
    from t0
),
t2 as (
    select row(spanName, serviceName) as table_row
    from t1
),
t3 as (
    select get_patterns(table_row, ARRAY['spanName', 'serviceName']) as ret
    from t2
)
select * from t3
"""

        start_timestamp = int(
            datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S").timestamp()
        )
        end_timestamp = int(
            datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S").timestamp()
        )

        logs = sls_client_manager.execute_query(
            pattern_query, start_timestamp, end_timestamp, 1000
        )

        if not logs:
            return None

        for log in logs:
            if "ret" in log:
                return log["ret"]

        return None

    def _execute_diff_patterns_query(
        self, start_time: str, end_time: str, span_conditions: str
    ) -> Optional[any]:
        """æ‰§è¡Œdiff_patternsæŸ¥è¯¢"""
        param_str = '{"minimum_support_fraction": 0.03}'
        diff_pattern_query = f"""
statusCode>0 | set session enable_remote_functions=true ;
set session velox_support_row_constructor_enabled=true;
with t0 as (
    select spanName, serviceName,
           JSON_EXTRACT_SCALAR(resources, '$["k8s.pod.ip"]') AS pod_ip,
           JSON_EXTRACT_SCALAR(resources, '$["k8s.node.name"]') AS node_name,
           JSON_EXTRACT_SCALAR(resources, '$["service.version"]') AS service_version,
           if(({span_conditions}), 'true', 'false') as anomaly_label,
           cast(if((statusCode = 2 or statusCode = 3), 1, 0) as double) as error_count
    from log
),
t1 as (
    select array_agg(spanName) as spanName,
           array_agg(serviceName) as serviceName,
           array_agg(pod_ip) as pod_ip,
           array_agg(node_name) as node_name,
           array_agg(service_version) as service_version,
           array_agg(anomaly_label) as anomaly_label,
           array_agg(error_count) as error_count
    from t0
),
t2 as (
    select row(serviceName, anomaly_label) as table_row
    from t1
),
t3 as (
    select diff_patterns(table_row, ARRAY['serviceName', 'anomaly_label'], 'anomaly_label', 'true', 'false', '', '', '{param_str}') as ret
    from t2
)
select * from t3
"""

        start_timestamp = int(
            datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S").timestamp()
        )
        end_timestamp = int(
            datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S").timestamp()
        )

        logs = sls_client_manager.execute_query(
            diff_pattern_query, start_timestamp, end_timestamp, 1000
        )

        if not logs:
            return None

        for log in logs:
            if "ret" in log:
                return log["ret"]

        return None

    def _parse_service_from_evidence(
        self,
        get_patterns_result: any,
        diff_patterns_result: any,
        candidate_root_causes: List[str],
    ) -> str:
        """è§£ææœåŠ¡è¯æ® - ä¸STS_Root_Cause_Analysis_Error.pyé€»è¾‘ä¸€è‡´"""
        target_service = "unknown"

        # æå–å€™é€‰æœåŠ¡ï¼ˆåªè€ƒè™‘.Failureç±»å‹ï¼‰
        candidate_services = set()
        if candidate_root_causes:
            for candidate in candidate_root_causes:
                if "." in candidate and candidate.endswith(".Failure"):
                    service_name = candidate.split(".")[0]
                    candidate_services.add(service_name)

        logger.info("ğŸ¯ é™åˆ¶åˆ†æåˆ°å€™é€‰æœåŠ¡: %s", list(candidate_services))

        # è§£æget_patternsç»“æœ - åªè€ƒè™‘å€™é€‰æœåŠ¡
        if get_patterns_result:
            try:
                if isinstance(get_patterns_result, str):
                    data_str = get_patterns_result.replace("null", "None")
                    result = eval(data_str)
                else:
                    result = get_patterns_result

                if (
                    len(result) >= 2
                    and isinstance(result[0], list)
                    and isinstance(result[1], list)
                ):
                    service_patterns = result[0]
                    service_counts = result[1]

                    # åªæŸ¥æ‰¾å€™é€‰æœåŠ¡ - å¿½ç•¥å…¶ä»–æœåŠ¡
                    candidate_matches = []

                    for i, pattern in enumerate(service_patterns):
                        if i < len(service_counts):
                            count = service_counts[i]
                            if "serviceName=" in pattern:
                                service = pattern.split("serviceName=")[1].strip("\"'")

                                # åªè€ƒè™‘å€™é€‰æœåŠ¡
                                if service in candidate_services:
                                    candidate_matches.append((service, count))
                                    logger.info(
                                        "ğŸ¯ æ‰¾åˆ°å€™é€‰æœåŠ¡: %s (é”™è¯¯æ•°: %d)",
                                        service,
                                        count,
                                    )
                                else:
                                    logger.info("âŒ å¿½ç•¥éå€™é€‰æœåŠ¡: %s", service)

                    # ä½¿ç”¨é”™è¯¯æ•°æœ€é«˜çš„å€™é€‰æœåŠ¡
                    if candidate_matches:
                        best_candidate = max(candidate_matches, key=lambda x: x[1])
                        target_service = best_candidate[0]
                        logger.info(
                            "âœ… é€‰æ‹©å€™é€‰æœåŠ¡: %s (é”™è¯¯æ•°: %d)",
                            target_service,
                            best_candidate[1],
                        )
                    else:
                        logger.info("âŒ åœ¨é”™è¯¯æ¨¡å¼ä¸­æœªæ‰¾åˆ°å€™é€‰æœåŠ¡")
                        return "unknown"

            except Exception as e:
                logger.error("âš ï¸ get_patternsç»“æœè§£æå¤±è´¥: %s", e)

        # è§£ædiff_patternsç»“æœ
        if diff_patterns_result:
            try:
                if isinstance(diff_patterns_result, str):
                    data_str = diff_patterns_result.replace("null", "None")
                    result = eval(data_str)
                else:
                    result = diff_patterns_result

                if len(result) >= 1 and isinstance(result[0], list):
                    anomaly_patterns = result[0]

                    for pattern in anomaly_patterns:
                        if "serviceName" in pattern and "=" in pattern:
                            service = pattern.split("='")[1].strip("'\"")
                            logger.info("âœ… diff_patternsç¡®è®¤å¼‚å¸¸æœåŠ¡: %s", service)

                            if service == target_service:
                                logger.info(
                                    "âœ… å¤šé‡è¯æ®ç¡®è®¤: %s æ˜¯ä¸»è¦æ ¹å› æœåŠ¡", service
                                )
                                return target_service
                            elif target_service == "unknown":
                                target_service = service
                                return target_service

            except Exception as e:
                logger.error("âš ï¸ diff_patternsç»“æœè§£æå¤±è´¥: %s", e)

        if target_service != "unknown":
            return target_service
        else:
            logger.info("âŒ æ— æ³•ä»è¿è¡Œæ—¶è¯æ®ä¸­æå–æ˜ç¡®çš„ç›®æ ‡æœåŠ¡")
            return "unknown"


# å…¨å±€é”™è¯¯åˆ†æå™¨å®ä¾‹
error_analyzer = ErrorAnalyzer()
