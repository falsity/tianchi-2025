{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# SPLå¿«é€Ÿè¯Šæ–­é—®é¢˜æ ¹å› åˆ†æ-é”™\n",
    "\n",
    "æœ¬notebookåŸºäºã€Šå¦‚ä½•ç”¨SPLå¿«é€Ÿè¯Šæ–­é—®é¢˜æ ¹å›  -- é”™ã€‹æ–‡æ¡£ï¼Œå®ç°äº†ä¸€ä¸ªå¯åˆ†æ­¥æ‰§è¡Œçš„æ•…éšœè¯Šæ–­æµç¨‹ã€‚\n",
    "\n",
    "## åˆ†ææµç¨‹\n",
    "1. **é…ç½®ç¯å¢ƒ** - è®¾ç½®SLSè®¿é—®å‡­è¯å’Œå‚æ•°\n",
    "2. **ç­›é€‰æŠ¥é”™spanId** - åˆ›å»ºSLSå®¢æˆ·ç«¯ï¼Œæ‰¾å‡ºæ•…éšœæ—¶é—´æ®µå†…çš„æ ¹å› span  \n",
    "3. **å¯»æ‰¾æŠ¥é”™ç‰¹å¾** - ä½¿ç”¨æ¨¡å¼åŒ¹é…åˆ†æé”™è¯¯ç‰¹å¾\n",
    "4. **äº¤å‰éªŒè¯æ—¥å¿—ç‰¹å¾** - éªŒè¯æ•…éšœæ ¹å› \n",
    "5. **æ ¹å› åˆ†ææ€»ç»“** - è®¡ç®—å…·ä½“çš„æ ¹å› å€™é€‰é¡¹\n",
    "\n",
    "## ä½¿ç”¨æ–¹æ³•\n",
    "åªéœ€åœ¨ç¬¬2ä¸ªcellä¸­ä¿®æ”¹FAULT_START_TIMEå’ŒFAULT_END_TIMEä¸ºæ‚¨çš„æ•…éšœæ—¶é—´æ®µï¼Œç„¶åæŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰cellå³å¯å¾—åˆ°æ ¹å› åˆ†æç»“æœã€‚\n",
    "\n",
    "notebookä¼šè‡ªåŠ¨ä»è¿è¡Œæ—¶è¯æ®ä¸­åˆ†æå¹¶ç¡®å®šå…·ä½“çš„æ ¹å› æœåŠ¡ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. é…ç½®ç¯å¢ƒ\n",
    "\n",
    "è®¾ç½®æ•…éšœæ—¶é—´æ®µå’ŒSLSå‚æ•°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•…éšœæ—¶é—´æ®µ: 2025-08-28 15:08:03 ~ 2025-08-28 15:13:03\n",
      "SLSé¡¹ç›®: proj-xtrace-a46b97cfdc1332238f714864c014a1b-cn-qingdao\n",
      "æ—¥å¿—åº“: logstore-tracing\n",
      "åŒºåŸŸ: cn-qingdao\n",
      "âœ… SLSè®¿é—®å‡­è¯é…ç½®æ­£ç¡®\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from aliyun.log import LogClient\n",
    "from alibabacloud_sts20150401.client import Client as StsClient\n",
    "from alibabacloud_sts20150401 import models as sts_models\n",
    "from alibabacloud_tea_openapi import models as open_api_models\n",
    "from Tea.exceptions import TeaException\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "# åˆ†ææ—¶é—´åŒºé—´\n",
    "FAULT_START_TIME = \"2025-08-28 15:08:03\"\n",
    "FAULT_END_TIME = \"2025-08-28 15:13:03\"\n",
    "\n",
    "# SLSé…ç½®å‚æ•° (æ—¥å¿—æ•°æ®å­˜å‚¨çš„ä½ç½®)\n",
    "PROJECT_NAME = \"proj-xtrace-a46b97cfdc1332238f714864c014a1b-cn-qingdao\"\n",
    "LOGSTORE_NAME = \"logstore-tracing\"\n",
    "REGION = \"cn-qingdao\"\n",
    "\n",
    "print(f\"æ•…éšœæ—¶é—´æ®µ: {FAULT_START_TIME} ~ {FAULT_END_TIME}\")\n",
    "print(f\"SLSé¡¹ç›®: {PROJECT_NAME}\")\n",
    "print(f\"æ—¥å¿—åº“: {LOGSTORE_NAME}\")\n",
    "print(f\"åŒºåŸŸ: {REGION}\")\n",
    "# ----------è¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæ ·ä¾‹å¦‚ä¸‹:\n",
    "# export ALIBABA_CLOUD_ACCESS_KEY_ID=\"ä½ ä¿å­˜çš„AccessKey ID\"\n",
    "# export ALIBABA_CLOUD_ACCESS_KEY_SECRET=\"ä½ ä¿å­˜çš„AccessKey Secret\"\n",
    "MAIN_ACCOUNT_ACCESS_KEY_ID = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_ID')\n",
    "MAIN_ACCOUNT_ACCESS_KEY_SECRET = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_SECRET')\n",
    "ALIBABA_CLOUD_ROLE_ARN = os.getenv('ALIBABA_CLOUD_ROLE_ARN','acs:ram::1672753017899339:role/tianchi-user-a')\n",
    "STS_SESSION_NAME = os.getenv('ALIBABA_CLOUD_ROLE_SESSION_NAME', 'my-sls-access') # è‡ªå®šä¹‰ä¼šè¯åç§°ï¼Œæ²¡æœ‰å›ºå®šå‘½åè¦æ±‚\n",
    "\n",
    "if MAIN_ACCOUNT_ACCESS_KEY_ID and MAIN_ACCOUNT_ACCESS_KEY_SECRET and ALIBABA_CLOUD_ROLE_ARN:\n",
    "    print(\"âœ… SLSè®¿é—®å‡­è¯é…ç½®æ­£ç¡®\")\n",
    "else:\n",
    "    print(\"âŒ è¯·é…ç½®ç¯å¢ƒå˜é‡ ALIBABA_CLOUD_ACCESS_KEY_ID å’Œ ALIBABA_CLOUD_ACCESS_KEY_SECRET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. ç­›é€‰æŠ¥é”™spanId\n",
    "\n",
    "åˆ›å»ºSLSå®¢æˆ·ç«¯ï¼Œä½¿ç”¨FindRootCauseSpansæŸ¥æ‰¾æ•…éšœæ—¶é—´æ®µå†…çš„æ ¹å› span\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- å¼€å§‹æ‰§è¡Œæ ¹å› SPANæŸ¥æ‰¾ä»»åŠ¡ ---\n",
      "âœ… æˆåŠŸè·å–è®¿é—®æƒé™ï¼\n",
      "âœ… SLSå®¢æˆ·ç«¯å·²ä½¿ç”¨ä¸´æ—¶å‡­è¯åˆ›å»ºã€‚\n",
      "[FindRootCauseSpans] åˆå§‹åŒ–å®Œæˆã€‚\n",
      "  å¼€å§‹æ—¶é—´: 2025-08-28 15:08:03 (æ—¶é—´æˆ³: 1756364883)\n",
      "  ç»“æŸæ—¶é—´: 2025-08-28 15:13:03 (æ—¶é—´æˆ³: 1756365183)\n",
      "\n",
      "å¼€å§‹æŸ¥æ‰¾æ ¹å› spans...\n",
      "proj-xtrace-a46b97cfdc1332238f714864c014a1b-cn-qingdao logstore-tracing cn-qingdao\n",
      "[FindRootCauseSpans] æŸ¥è¯¢æ—¶é—´èŒƒå›´: 2025-08-28 15:08:03 ~ 2025-08-28 15:13:03. æŸ¥è¯¢æ¡ä»¶: statusCode>1\n",
      "æ€»å…±æŸ¥è¯¢åˆ°çš„spanæ•°é‡: 1522\n",
      "æ¶‰åŠçš„traceæ•°é‡: 154\n",
      "\n",
      "æ‰¾åˆ° 154 ä¸ªæ ¹å› span:\n",
      "1. a83bb1e960e12216\n",
      "2. 76af7f3f7141bbf1\n",
      "3. 2d27a4a14d01d2da\n",
      "4. 7c3d14ba208aba2d\n",
      "5. 149605380d997ed7\n",
      "6. 8f63518d7e900af7\n",
      "7. 4a88854bf7632fdf\n",
      "8. b7640166a3e0bf26\n",
      "9. cbeb0704d0ea7c37\n",
      "10. 529e883159d97406\n",
      "... è¿˜æœ‰ 144 ä¸ª\n"
     ]
    }
   ],
   "source": [
    "from find_root_cause_spans_error import FindRootCauseSpans\n",
    "\n",
    "def get_sts_credentials():\n",
    "\n",
    "\n",
    "    if not all([MAIN_ACCOUNT_ACCESS_KEY_ID, MAIN_ACCOUNT_ACCESS_KEY_SECRET, ALIBABA_CLOUD_ROLE_ARN]):\n",
    "        print(\"âŒ è§’è‰²ARNç¼ºå¤±! è¯·åœ¨ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸­é…ç½® ALIBABA_CLOUD_ACCESS_KEY_ID, ALIBABA_CLOUD_ACCESS_KEY_SECRET\")\n",
    "        return None\n",
    "\n",
    "    config = open_api_models.Config(\n",
    "        access_key_id=MAIN_ACCOUNT_ACCESS_KEY_ID,\n",
    "        access_key_secret=MAIN_ACCOUNT_ACCESS_KEY_SECRET,\n",
    "        endpoint=f'sts.{REGION}.aliyuncs.com'\n",
    "    )\n",
    "    sts_client = StsClient(config)\n",
    "\n",
    "    assume_role_request = sts_models.AssumeRoleRequest(\n",
    "        role_arn=ALIBABA_CLOUD_ROLE_ARN,\n",
    "        role_session_name=STS_SESSION_NAME,\n",
    "        duration_seconds=3600\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = sts_client.assume_role(assume_role_request)\n",
    "        print(\"âœ… æˆåŠŸè·å–è®¿é—®æƒé™ï¼\")\n",
    "        return response.body.credentials\n",
    "    except TeaException as e:\n",
    "        print(f\"âŒ è·å–STSä¸´æ—¶å‡­è¯å¤±è´¥: {e.message}\")\n",
    "        print(f\"  é”™è¯¯ç : {e.code}\")\n",
    "        print(\"  è¯·æ£€æŸ¥:1. ä¸»è´¦å·AKæ˜¯å¦æ­£ç¡®;2. ç›®æ ‡è§’è‰²ARNæ˜¯å¦æ­£ç¡®;3. ç›®æ ‡è§’è‰²çš„ä¿¡ä»»ç­–ç•¥æ˜¯å¦å·²é…ç½®ä¸ºä¿¡ä»»æ‚¨çš„ä¸»è´¦å·ã€‚\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯åœ¨è·å–STSå‡­è¯æ—¶: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- å‡½æ•°ï¼šåˆ›å»ºSLSå®¢æˆ·ç«¯ ---\n",
    "def create_sls_client_with_sts():\n",
    "\n",
    "    sts_credentials = get_sts_credentials()\n",
    "\n",
    "    if not sts_credentials:\n",
    "        return None\n",
    "\n",
    "    sls_endpoint = f\"{REGION}.log.aliyuncs.com\"\n",
    "\n",
    "    # aliyun-log-python-sdk ä½¿ç”¨ securityToken å‚æ•°\n",
    "    log_client = LogClient(\n",
    "        endpoint=sls_endpoint,\n",
    "        accessKeyId=sts_credentials.access_key_id,\n",
    "        accessKey=sts_credentials.access_key_secret,\n",
    "        securityToken=sts_credentials.security_token\n",
    "    )\n",
    "\n",
    "    print(\"âœ… SLSå®¢æˆ·ç«¯å·²ä½¿ç”¨ä¸´æ—¶å‡­è¯åˆ›å»ºã€‚\")\n",
    "    return log_client\n",
    "\n",
    "print(\"--- å¼€å§‹æ‰§è¡Œæ ¹å› SPANæŸ¥æ‰¾ä»»åŠ¡ ---\")\n",
    "\n",
    "# 1. åˆ›å»ºå¸¦æœ‰STSå‡­è¯çš„SLSå®¢æˆ·ç«¯\n",
    "log_client_instance = create_sls_client_with_sts()\n",
    "\n",
    "# 2. å¦‚æœå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸï¼Œåˆ™å¼€å§‹æ‰§è¡ŒæŸ¥æ‰¾æ ¹å› spanä»»åŠ¡\n",
    "if log_client_instance:\n",
    "    # 3. åˆ›å»ºæ ¹å› spanæŸ¥æ‰¾å™¨ï¼Œä¼ å…¥å®¢æˆ·ç«¯å®ä¾‹\n",
    "    root_cause_finder = FindRootCauseSpans(\n",
    "        client=log_client_instance,\n",
    "        project_name=PROJECT_NAME,\n",
    "        logstore_name=LOGSTORE_NAME,\n",
    "        region=REGION,\n",
    "        start_time=FAULT_START_TIME,\n",
    "        end_time=FAULT_END_TIME\n",
    "    )\n",
    "\n",
    "    print(\"\\nå¼€å§‹æŸ¥æ‰¾æ ¹å› spans...\")\n",
    "    try:\n",
    "        root_cause_span_ids = root_cause_finder.find_root_cause_spans()\n",
    "\n",
    "        print(f\"\\næ‰¾åˆ° {len(root_cause_span_ids)} ä¸ªæ ¹å› span:\")\n",
    "        for i, span_id in enumerate(root_cause_span_ids[:10]):\n",
    "            print(f\"{i+1}. {span_id}\")\n",
    "\n",
    "        if len(root_cause_span_ids) > 10:\n",
    "            print(f\"... è¿˜æœ‰ {len(root_cause_span_ids) - 10} ä¸ª\")\n",
    "    except TeaException as e:\n",
    "        print(f\"\\nâŒ æŸ¥è¯¢æ—¥å¿—æ—¶å‘ç”Ÿé”™è¯¯: {e.message}\")\n",
    "        print(f\"  é”™è¯¯ç : {e.code}\")\n",
    "        print(\"  è¯·æ£€æŸ¥ï¼š1. ä¸´æ—¶å‡­è¯æ˜¯å¦å·²è¿‡æœŸï¼›2. æ‰®æ¼”çš„è§’è‰²æ˜¯å¦æ‹¥æœ‰å¯¹ç›®æ ‡Projectå’ŒLogstoreçš„è¯»æƒé™ã€‚\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ æŸ¥è¯¢æ—¥å¿—æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nâŒ å› æ— æ³•åˆ›å»ºSLSå®¢æˆ·ç«¯ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. ç”ŸæˆSPLæŸ¥è¯¢æ¡ä»¶\n",
    "\n",
    "å°†æ ¹å› span IDè½¬æ¢ä¸ºSPLæŸ¥è¯¢æ¡ä»¶æ ¼å¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”Ÿæˆçš„spanIdæŸ¥è¯¢åˆ—è¡¨:\n",
      "spanId='a83bb1e960e12216' or spanId='76af7f3f7141bbf1' or spanId='2d27a4a14d01d2da' or spanId='7c3d14ba208aba2d' or spanId='149605380d997ed7' or spanId='8f63518d7e900af7' or spanId='4a88854bf7632fdf' or spanId='b7640166a3e0bf26' or spanId='cbeb0704d0ea7c37' or spanId='529e883159d97406' or spanId='00d547ce56971266' or spanId='d6323829b16e4487' or spanId='615c90a7fb37a021' or spanId='e3f22206b6ecab24' or spanId='99ee8078b1864cbd' or spanId='3b82e6f4458fba65' or spanId='4aac6cf2bb6b9c16' or spanId=...\n",
      "\n",
      "âœ… æŸ¥è¯¢æ¡ä»¶å·²ä¿å­˜ï¼ŒåŒ…å« 154 ä¸ªspanId\n"
     ]
    }
   ],
   "source": [
    "# ç”ŸæˆspanIdæŸ¥è¯¢æ¡ä»¶\n",
    "if root_cause_span_ids:\n",
    "    span_conditions = \" or \".join([f\"spanId='{span_id}'\" for span_id in root_cause_span_ids])\n",
    "    print(\"ç”Ÿæˆçš„spanIdæŸ¥è¯¢åˆ—è¡¨:\")\n",
    "    print(span_conditions[:500] + \"...\" if len(span_conditions) > 500 else span_conditions)\n",
    "\n",
    "    # ä¿å­˜åˆ°å˜é‡ä¾›åç»­ä½¿ç”¨\n",
    "    SPAN_CONDITIONS = span_conditions\n",
    "    print(f\"\\nâœ… æŸ¥è¯¢æ¡ä»¶å·²ä¿å­˜ï¼ŒåŒ…å« {len(root_cause_span_ids)} ä¸ªspanId\")\n",
    "else:\n",
    "    print(\"âŒ æœªæ‰¾åˆ°æ ¹å› spanï¼Œæ— æ³•ç”ŸæˆæŸ¥è¯¢æ¡ä»¶\")\n",
    "    SPAN_CONDITIONS = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. å¯»æ‰¾æŠ¥é”™ç‰¹å¾\n",
    "\n",
    "### 4.1 ä½¿ç”¨SPLæ¨¡å¼åŒ¹é…åˆ†æé”™è¯¯ç‰¹å¾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰§è¡Œé”™è¯¯ç‰¹å¾åˆ†ææŸ¥è¯¢...\n",
      "\n",
      "é”™è¯¯ç‰¹å¾åˆ†æç»“æœ (1 æ¡è®°å½•):\n",
      "ret: [[\"serviceName=payment\",\"serviceName=frontend-proxy\"],[152,2],null,null]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from aliyun.log import GetLogsRequest\n",
    "from datetime import datetime\n",
    "\n",
    "if SPAN_CONDITIONS:\n",
    "    # ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„SLSå®¢æˆ·ç«¯\n",
    "    client = log_client_instance\n",
    "    # æ„å»ºé”™è¯¯ç‰¹å¾åˆ†ææŸ¥è¯¢,å…³é”®æ˜¯è°ƒç”¨é˜¿é‡Œäº‘SLSæä¾›çš„æ™ºèƒ½åˆ†æå‡½æ•°get_patterns,è‡ªåŠ¨åˆ†ææ•°æ®çš„ç»„åˆï¼Œæ‰¾å‡ºå…¶ä¸­å‡ºç°é¢‘ç‡æœ€é«˜çš„æ¨¡å¼\n",
    "    pattern_analysis_query = f\"\"\"\n",
    "* | set session enable_remote_functions=true ;\n",
    "set session velox_support_row_constructor_enabled=true;\n",
    "with t0 as (\n",
    "    select spanName, serviceName,\n",
    "           JSON_EXTRACT_SCALAR(resources, '$[\"k8s.pod.ip\"]') AS pod_ip,\n",
    "           JSON_EXTRACT_SCALAR(resources, '$[\"k8s.node.name\"]') AS node_name,\n",
    "           JSON_EXTRACT_SCALAR(resources, '$[\"service.version\"]') AS service_version,\n",
    "           if((statusCode = 2 or statusCode = 3), 'true', 'false') as anomaly_label,\n",
    "           cast(if((statusCode = 2 or statusCode = 3), 1, 0) as double) as error_count\n",
    "    from log\n",
    "    where {SPAN_CONDITIONS}\n",
    "),\n",
    "t1 as (\n",
    "    select array_agg(spanName) as spanName,\n",
    "           array_agg(serviceName) as serviceName,\n",
    "           array_agg(pod_ip) as pod_ip,\n",
    "           array_agg(node_name) as node_name,\n",
    "           array_agg(service_version) as service_version,\n",
    "           array_agg(anomaly_label) as anomaly_label,\n",
    "           array_agg(error_count) as error_count\n",
    "    from t0\n",
    "),\n",
    "t2 as (\n",
    "    select row(spanName, serviceName) as table_row\n",
    "    from t1\n",
    "),\n",
    "t3 as (\n",
    "    select get_patterns(table_row, ARRAY['spanName', 'serviceName']) as ret\n",
    "    from t2\n",
    ")\n",
    "select * from t3\n",
    "\"\"\"\n",
    "\n",
    "    print(\"æ‰§è¡Œé”™è¯¯ç‰¹å¾åˆ†ææŸ¥è¯¢...\")\n",
    "\n",
    "    # æ—¶é—´æ ¼å¼è½¬æ¢\n",
    "    start_timestamp = int(datetime.strptime(FAULT_START_TIME, \"%Y-%m-%d %H:%M:%S\").timestamp())\n",
    "    end_timestamp = int(datetime.strptime(FAULT_END_TIME, \"%Y-%m-%d %H:%M:%S\").timestamp())\n",
    "\n",
    "    request = GetLogsRequest(\n",
    "        project=PROJECT_NAME,\n",
    "        logstore=LOGSTORE_NAME,\n",
    "        query=pattern_analysis_query,\n",
    "        fromTime=start_timestamp,\n",
    "        toTime=end_timestamp,\n",
    "        line=1000\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.get_logs(request)\n",
    "        if response and response.get_count() > 0:\n",
    "            print(f\"\\né”™è¯¯ç‰¹å¾åˆ†æç»“æœ ({response.get_count()} æ¡è®°å½•):\")\n",
    "\n",
    "            # ä¿å­˜get_patternsç»“æœç”¨äºåç»­åˆ†æ\n",
    "            global get_patterns_result\n",
    "            get_patterns_result = None\n",
    "\n",
    "            for log in response.get_logs():\n",
    "                contents = log.get_contents()\n",
    "                for key, value in contents.items():\n",
    "                    print(f\"{key}: {value}\")\n",
    "                    if key == \"ret\":\n",
    "                        get_patterns_result = value  # ä¿å­˜ç»“æœä¾›åç»­è§£æ\n",
    "                print(\"-\" * 50)\n",
    "        else:\n",
    "            print(\"æœªæ‰¾åˆ°é”™è¯¯ç‰¹å¾åˆ†æç»“æœ\")\n",
    "            get_patterns_result = None\n",
    "    except Exception as e:\n",
    "        print(f\"é”™è¯¯ç‰¹å¾åˆ†ææŸ¥è¯¢å¤±è´¥: {e}\")\n",
    "        get_patterns_result = None\n",
    "else:\n",
    "    print(\"âŒ æ— æœ‰æ•ˆçš„spanIdæ¡ä»¶ï¼Œè·³è¿‡é”™è¯¯ç‰¹å¾åˆ†æ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ä½¿ç”¨diff_patternsåˆ†æå¼‚å¸¸ç‰¹å¾å·®å¼‚\n",
    "\n",
    "ä½¿ç”¨diff_patternså‡½æ•°åˆ†ææ ¹å› spanä¸éæ ¹å› é”™è¯¯spançš„å·®å¼‚ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰§è¡Œdiff_patternså·®å¼‚æ¨¡å¼åˆ†ææŸ¥è¯¢...\n",
      "\\nå·®å¼‚æ¨¡å¼åˆ†æç»“æœ (1 æ¡è®°å½•):\n",
      "ret: [[\"\\\"serviceName\\\"='payment'\"],[152],[0],[0.987012987012987],[0.0],[0.987012987012987],[1.0],[0.0],null]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨diff_patternså‡½æ•°åˆ†ææ ¹å› spanä¸éæ ¹å› é”™è¯¯spançš„å·®å¼‚ç‰¹å¾\n",
    "# - å¼‚å¸¸ç»„('true'): æ ¹å› span (åœ¨SPAN_CONDITIONSåˆ—è¡¨ä¸­çš„span)\n",
    "# - å¯¹ç…§ç»„('false'): éæ ¹å› çš„é”™è¯¯span (statusCode>0ä½†ä¸åœ¨æ ¹å› åˆ—è¡¨ä¸­çš„span)\n",
    "# ğŸ¯ åˆ†æç›®çš„:\n",
    "# - æ‰¾å‡ºæ ¹å› spanä¸å…¶ä»–é”™è¯¯spanåœ¨æœåŠ¡åç­‰ç»´åº¦ä¸Šçš„å·®å¼‚æ¨¡å¼\n",
    "# - è¯†åˆ«æ ¹å› spançš„ç‹¬ç‰¹ç‰¹å¾ï¼Œå¸®åŠ©éªŒè¯æ ¹å› è¯†åˆ«çš„å‡†ç¡®æ€§\n",
    "if SPAN_CONDITIONS:\n",
    "    diff_pattern_query = f\"\"\"\n",
    "statusCode>0 | set session enable_remote_functions=true ;\n",
    "set session velox_support_row_constructor_enabled=true;\n",
    "with t0 as (\n",
    "    select spanName, serviceName,\n",
    "           JSON_EXTRACT_SCALAR(resources, '$[\"k8s.pod.ip\"]') AS pod_ip,\n",
    "           JSON_EXTRACT_SCALAR(resources, '$[\"k8s.node.name\"]') AS node_name,\n",
    "           JSON_EXTRACT_SCALAR(resources, '$[\"service.version\"]') AS service_version,\n",
    "           if(({SPAN_CONDITIONS}), 'true', 'false') as anomaly_label,\n",
    "           cast(if((statusCode = 2 or statusCode = 3), 1, 0) as double) as error_count\n",
    "    from log\n",
    "),\n",
    "t1 as (\n",
    "    select array_agg(spanName) as spanName,\n",
    "           array_agg(serviceName) as serviceName,\n",
    "           array_agg(pod_ip) as pod_ip,\n",
    "           array_agg(node_name) as node_name,\n",
    "           array_agg(service_version) as service_version,\n",
    "           array_agg(anomaly_label) as anomaly_label,\n",
    "           array_agg(error_count) as error_count\n",
    "    from t0\n",
    "),\n",
    "t2 as (\n",
    "    select row(serviceName, anomaly_label) as table_row\n",
    "    from t1\n",
    "),\n",
    "t3 as (\n",
    "    select diff_patterns(table_row, ARRAY['serviceName', 'anomaly_label'], 'anomaly_label', 'true', 'false') as ret\n",
    "    from t2\n",
    ")\n",
    "select * from t3\n",
    "\"\"\"\n",
    "\n",
    "    print(\"æ‰§è¡Œdiff_patternså·®å¼‚æ¨¡å¼åˆ†ææŸ¥è¯¢...\")\n",
    "\n",
    "    request = GetLogsRequest(\n",
    "        project=PROJECT_NAME,\n",
    "        logstore=LOGSTORE_NAME,\n",
    "        query=diff_pattern_query,\n",
    "        fromTime=start_timestamp, #- 5*60,\n",
    "        toTime=end_timestamp,\n",
    "        line=1000\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.get_logs(request)\n",
    "        if response and response.get_count() > 0:\n",
    "            print(f\"\\\\nå·®å¼‚æ¨¡å¼åˆ†æç»“æœ ({response.get_count()} æ¡è®°å½•):\")\n",
    "\n",
    "            # ä¿å­˜diff_patternsç»“æœç”¨äºåç»­åˆ†æ\n",
    "            global diff_patterns_result\n",
    "            diff_patterns_result = None\n",
    "\n",
    "            for log in response.get_logs():\n",
    "                contents = log.get_contents()\n",
    "                for key, value in contents.items():\n",
    "                    print(f\"{key}: {value}\")\n",
    "                    if key == \"ret\":\n",
    "                        diff_patterns_result = value  # ä¿å­˜ç»“æœä¾›åç»­è§£æ\n",
    "                print(\"-\" * 50)\n",
    "        else:\n",
    "            print(\"æœªæ‰¾åˆ°å·®å¼‚æ¨¡å¼åˆ†æç»“æœ\")\n",
    "            diff_patterns_result = None\n",
    "    except Exception as e:\n",
    "        print(f\"å·®å¼‚æ¨¡å¼åˆ†ææŸ¥è¯¢å¤±è´¥: {e}\")\n",
    "        diff_patterns_result = None\n",
    "else:\n",
    "    print(\"âŒ æ— æœ‰æ•ˆçš„spanIdæ¡ä»¶ï¼Œè·³è¿‡å·®å¼‚æ¨¡å¼åˆ†æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. äº¤å‰éªŒè¯æ—¥å¿—ç‰¹å¾\n",
    "\n",
    "ä½¿ç”¨get_log_patternsåˆ†ææ•…éšœæ—¶é—´æ®µå†…çš„æ—¥å¿—æ¨¡å¼ï¼ŒéªŒè¯æ ¹å› \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰§è¡Œæ—¥å¿—æ¨¡å¼åˆ†ææŸ¥è¯¢...\n",
      "ç¬¬ä¸€é˜¶æ®µï¼šè·å–model_id...\n",
      "âœ… æˆåŠŸè·å–model_id: 1593c527-e17b-4202-91d1-19b202975f36\n",
      "é”™è¯¯ä¿¡æ¯: null\n",
      "ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨model_idè¿›è¡Œæ¨¡å¼åŒ¹é…...\n",
      "\\nâœ… æ—¥å¿—æ¨¡å¼åŒ¹é…ç»“æœ (15554 æ¡è®°å½•):\n",
      "\\nğŸ” ä¸»è¦æ—¥å¿—æ¨¡å¼ (æŒ‰å‡ºç°é¢‘ç‡æ’åº):\n",
      "æ³¨æ„: åªæ˜¾ç¤ºæœåŠ¡åçš„æ¨¡å¼é€šå¸¸è¡¨ç¤ºè¯¥æœåŠ¡çš„statusMessageä¸ºç©º\n",
      "æœ‰å…·ä½“é”™è¯¯ä¿¡æ¯çš„æ¨¡å¼æ›´å¯èƒ½æŒ‡å‘çœŸæ­£çš„æ ¹å› \n",
      "å‡ºç°æ¬¡æ•°: 15250\n",
      "æ¨¡å¼: [<*>] \n",
      "--------------------------------------------------------------------------------\n",
      "å‡ºç°æ¬¡æ•°: 152\n",
      "æ¨¡å¼: [checkout] Payment request failed. Invalid token. app.loyalty.level=gold\n",
      "--------------------------------------------------------------------------------\n",
      "å‡ºç°æ¬¡æ•°: 152\n",
      "æ¨¡å¼: [checkout] rpc error: code = Internal desc = failed to charge card: could not charge the card: rpc error: code = Unknown desc = Payment request failed. Invalid token. app.loyalty.level=gold\n",
      "--------------------------------------------------------------------------------\n",
      "\\nğŸ“Š æ¶‰åŠçš„æœåŠ¡æ’åº (æŒ‰é”™è¯¯é¢‘ç‡):\n",
      "currency: 13418 æ¬¡é”™è¯¯\n",
      "checkout: 918 æ¬¡é”™è¯¯\n",
      "frontend: 608 æ¬¡é”™è¯¯\n",
      "frontend-proxy: 306 æ¬¡é”™è¯¯\n",
      "load-generator: 152 æ¬¡é”™è¯¯\n",
      "payment: 152 æ¬¡é”™è¯¯\n"
     ]
    }
   ],
   "source": [
    "# æ—¥å¿—æ¨¡å¼åˆ†ææŸ¥è¯¢ - ä½¿ç”¨ä¸¤é˜¶æ®µæŸ¥è¯¢æ–¹æ³•\n",
    "\n",
    "# ä½¿ç”¨é˜¿é‡Œäº‘SLSçš„æ™ºèƒ½æ¨¡å¼è¯†åˆ«åŠŸèƒ½ï¼Œé€šè¿‡ä¸¤é˜¶æ®µæŸ¥è¯¢åˆ†ææ—¥å¿—æ¨¡å¼ï¼š\n",
    "# 1. ç¬¬ä¸€é˜¶æ®µï¼šåŸºäºæ‰€æœ‰é”™è¯¯æ—¥å¿—ï¼Œè®­ç»ƒç”Ÿæˆæ—¥å¿—æ¨¡å¼æ¨¡å‹\n",
    "# 2. ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ŒåŒ¹é…å’Œè¯†åˆ«å…·ä½“çš„æ—¥å¿—æ¨¡å¼\n",
    "\n",
    "print(\"æ‰§è¡Œæ—¥å¿—æ¨¡å¼åˆ†ææŸ¥è¯¢...\")\n",
    "\n",
    "# ç¬¬ä¸€é˜¶æ®µï¼šè·å–model_id\n",
    "log_pattern_query_stage1 = \"\"\"\n",
    "statusCode > 0 | set session enable_remote_functions=true;\n",
    "set session velox_support_row_constructor_enabled=true;\n",
    "\n",
    "with t0 as (\n",
    "  select statusCode, statusMessage, serviceName,\n",
    "         CONCAT('[', serviceName, '] ', statusMessage) as combined_message\n",
    "  from log\n",
    "),\n",
    "t1 as (\n",
    "  select array_agg(combined_message) as contents\n",
    "  from t0\n",
    "),\n",
    "t2 as (\n",
    "  -- è°ƒç”¨get_log_patternså‡½æ•°è¿›è¡Œæ¨¡å¼å­¦ä¹ \n",
    "  select\n",
    "    contents,\n",
    "    get_log_patterns(contents, ARRAY[' ', '\\\\n', '\\\\t', '\\\\r', '\\\\f', '\\\\v', ':', ',', '[', ']'], null, null, '{\"threshold\": 3, \"tolerance\": 0.3, \"maxDigitRatio\": 0.3}') as ret\n",
    "  from t1\n",
    ")\n",
    "select\n",
    "  ret.model_id as model_id,\n",
    "  ret.error_msg as error_msg\n",
    "from t2\n",
    "\"\"\"\n",
    "\n",
    "print(\"ç¬¬ä¸€é˜¶æ®µï¼šè·å–model_id...\")\n",
    "stage1_request = GetLogsRequest(\n",
    "    project=PROJECT_NAME,\n",
    "    logstore=LOGSTORE_NAME,\n",
    "    query=log_pattern_query_stage1,\n",
    "    fromTime=start_timestamp,\n",
    "    toTime=end_timestamp,\n",
    "    line=10\n",
    ")\n",
    "\n",
    "try:\n",
    "    stage1_response = client.get_logs(stage1_request)\n",
    "    if stage1_response and stage1_response.get_count() > 0:\n",
    "        # è·å–model_id\n",
    "        first_log = stage1_response.get_logs()[0]\n",
    "        stage1_contents = first_log.get_contents()\n",
    "        model_id = stage1_contents.get(\"model_id\", \"\")\n",
    "        error_msg = stage1_contents.get(\"error_msg\", \"\")\n",
    "\n",
    "        print(f\"âœ… æˆåŠŸè·å–model_id: {model_id}\")\n",
    "        if error_msg:\n",
    "            print(f\"é”™è¯¯ä¿¡æ¯: {error_msg}\")\n",
    "\n",
    "        # ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨model_idè¿›è¡Œæ¨¡å¼åŒ¹é…\n",
    "        if model_id:\n",
    "            log_pattern_query_stage2 = f\"\"\"\n",
    "statusCode > 0 | set session presto_velox_mix_run_not_check_linked_agg_enabled=true;\n",
    "set session presto_velox_mix_run_support_complex_type_enabled=true;\n",
    "set session velox_sanity_limit_enabled=false;\n",
    "set session enable_remote_functions=true;\n",
    "\n",
    "with t0 as (\n",
    "    select CONCAT('[', serviceName, '] ', statusMessage) as combined_message\n",
    "    from log\n",
    ")\n",
    "select\n",
    "    ret.is_matched as is_matched,\n",
    "    ret.pattern_id as pattern_id,\n",
    "    ret.pattern as pattern,\n",
    "    ret.regexp as pattern_regexp,\n",
    "    ret.variables as variables,\n",
    "    combined_message as content\n",
    "from (\n",
    "    -- è°ƒç”¨match_log_patternså‡½æ•°ï¼Œä½¿ç”¨ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„model_idè¿›è¡ŒåŒ¹é…\n",
    "    select match_log_patterns('{model_id}', combined_message) as ret, combined_message\n",
    "    from t0\n",
    ")\n",
    "where ret.is_matched = true\n",
    "limit 50000\n",
    "\"\"\"\n",
    "\n",
    "            print(\"ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨model_idè¿›è¡Œæ¨¡å¼åŒ¹é…...\")\n",
    "            stage2_request = GetLogsRequest(\n",
    "                project=PROJECT_NAME,\n",
    "                logstore=LOGSTORE_NAME,\n",
    "                query=log_pattern_query_stage2,\n",
    "                fromTime=start_timestamp,\n",
    "                toTime=end_timestamp,\n",
    "                line=50000\n",
    "            )\n",
    "\n",
    "            stage2_response = client.get_logs(stage2_request)\n",
    "\n",
    "            if stage2_response and stage2_response.get_count() > 0:\n",
    "                print(f\"\\\\nâœ… æ—¥å¿—æ¨¡å¼åŒ¹é…ç»“æœ ({stage2_response.get_count()} æ¡è®°å½•):\")\n",
    "\n",
    "                # ===== ç»“æœç»Ÿè®¡å’Œåˆ†æ =====\n",
    "                pattern_counts = {}           # ç»Ÿè®¡æ¯ä¸ªæ¨¡å¼çš„å‡ºç°æ¬¡æ•°\n",
    "                service_pattern_counts = {}   # ç»Ÿè®¡æ¯ä¸ªæœåŠ¡çš„é”™è¯¯æ¬¡æ•°\n",
    "\n",
    "                for log in stage2_response.get_logs():\n",
    "                    contents = log.get_contents()\n",
    "                    pattern = contents.get('pattern', '')\n",
    "                    content = contents.get('content', '')\n",
    "\n",
    "                    if pattern:\n",
    "                        pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1\n",
    "\n",
    "                        # æå–æœåŠ¡åè¿›è¡Œç»Ÿè®¡\n",
    "                        if content.startswith('[') and ']' in content:\n",
    "                            service_name = content.split(']')[0][1:]  # æå–[serviceName]ä¸­çš„serviceName\n",
    "                            service_pattern_counts[service_name] = service_pattern_counts.get(service_name, 0) + 1\n",
    "\n",
    "                # æŒ‰å‡ºç°æ¬¡æ•°æ’åºæ˜¾ç¤º\n",
    "                sorted_patterns = sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "                sorted_services = sorted(service_pattern_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                # ===== å±•ç¤ºåˆ†æç»“æœ =====\n",
    "                print(\"\\\\nğŸ” ä¸»è¦æ—¥å¿—æ¨¡å¼ (æŒ‰å‡ºç°é¢‘ç‡æ’åº):\")\n",
    "                print(\"æ³¨æ„: åªæ˜¾ç¤ºæœåŠ¡åçš„æ¨¡å¼é€šå¸¸è¡¨ç¤ºè¯¥æœåŠ¡çš„statusMessageä¸ºç©º\")\n",
    "                print(\"æœ‰å…·ä½“é”™è¯¯ä¿¡æ¯çš„æ¨¡å¼æ›´å¯èƒ½æŒ‡å‘çœŸæ­£çš„æ ¹å› \")\n",
    "                for pattern, count in sorted_patterns[:10]:\n",
    "                    print(f\"å‡ºç°æ¬¡æ•°: {count}\")\n",
    "                    print(f\"æ¨¡å¼: {pattern}\")\n",
    "                    print(\"-\" * 80)\n",
    "\n",
    "                print(\"\\\\nğŸ“Š æ¶‰åŠçš„æœåŠ¡æ’åº (æŒ‰é”™è¯¯é¢‘ç‡):\")\n",
    "                for service, count in sorted_services[:10]:\n",
    "                    print(f\"{service}: {count} æ¬¡é”™è¯¯\")\n",
    "\n",
    "            else:\n",
    "                print(\"âŒ ç¬¬äºŒé˜¶æ®µï¼šæœªæ‰¾åˆ°åŒ¹é…çš„æ—¥å¿—æ¨¡å¼\")\n",
    "        else:\n",
    "            print(\"âŒ æ— æ³•è·å–æœ‰æ•ˆçš„model_id\")\n",
    "\n",
    "    else:\n",
    "        print(\"âŒ ç¬¬ä¸€é˜¶æ®µï¼šæœªæ‰¾åˆ°æ—¥å¿—æ¨¡å¼åˆ†æç»“æœ\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ—¥å¿—æ¨¡å¼åˆ†ææŸ¥è¯¢å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. ç»“æœæ€»ç»“\n",
    "\n",
    "æ±‡æ€»åˆ†æç»“æœå¹¶ç»™å‡ºè¯Šæ–­ç»“è®º\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Step 5: Root Cause Analysis Summary\n",
      "============================================================\n",
      "ğŸ“Š åˆ†ææ€»ç»“ï¼š\n",
      "   å¼‚å¸¸æ—¶é—´æ®µï¼š2025-08-28 15:08:03 ~ 2025-08-28 15:13:03\n",
      "   åˆ†æçš„SLSé¡¹ç›®ï¼šproj-xtrace-a46b97cfdc1332238f714864c014a1b-cn-qingdao\n",
      "   å‘ç°é”™è¯¯spanæ•°é‡ï¼š154\n",
      "\n",
      "ğŸ¯ æ ¹å› å‘ç°ï¼š\n",
      "   âœ… å·²æ‰¾åˆ° 154 ä¸ªé”™è¯¯span\n",
      "   âœ… get_patternså‘ç°ä¸»è¦é”™è¯¯æœåŠ¡: payment (é”™è¯¯æ•°: 152)\n",
      "   âœ… diff_patternsç¡®è®¤å¼‚å¸¸æœåŠ¡: payment\n",
      "   âœ… å¤šé‡è¯æ®ç¡®è®¤: payment æ˜¯ä¸»è¦æ ¹å› æœåŠ¡\n",
      "   âœ… æ ¹æ®è¿è¡Œæ—¶è¯æ®ç¡®å®šç›®æ ‡æœåŠ¡: payment\n",
      "\n",
      "ğŸ† æ ¹å› å€™é€‰ï¼š\n",
      "   ğŸ¯ payment\n",
      "   ğŸ“ˆ ç½®ä¿¡åº¦ï¼šé«˜\n",
      "   âœ… è¯æ®ï¼šTRUEï¼ˆå·²æ£€æµ‹åˆ°å¼‚å¸¸ï¼‰\n",
      "   ğŸ“ æ”¯æŒè¯æ®ï¼š\n",
      "      - å‘ç° 154 ä¸ªé”™è¯¯span\n",
      "      - diff_patternsåˆ†æè¡¨æ˜ payment æœåŠ¡å¼‚å¸¸\n",
      "      - æ—¥å¿—æ¨¡å¼åˆ†æéªŒè¯äº†æœåŠ¡é—®é¢˜\n",
      "      - é”™è¯¯ç‰¹å¾åˆ†æç¡®è®¤äº†æ ¹å› ä½ç½®\n",
      "\n",
      "ğŸ’¡ å»ºè®®ï¼š\n",
      "   - æ£€æŸ¥ payment æœåŠ¡çš„å¥åº·çŠ¶æ€\n",
      "   - æŸ¥çœ‹ payment çš„é”™è¯¯æ—¥å¿—å’Œå¼‚å¸¸\n",
      "   - éªŒè¯ payment çš„éƒ¨ç½²å’Œé…ç½®\n",
      "   - è€ƒè™‘é‡å¯æˆ–ä¿®å¤ payment æœåŠ¡\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ æœ€ç»ˆç­”å¤ï¼špayment\n",
      "ğŸ“ˆ ç½®ä¿¡åº¦ï¼šé«˜\n",
      "ğŸ” è¯æ®ï¼šTRUE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” Step 5: Root Cause Analysis Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# åˆ†æç»“æœæ€»ç»“\n",
    "print(f\"ğŸ“Š åˆ†ææ€»ç»“ï¼š\")\n",
    "print(f\"   å¼‚å¸¸æ—¶é—´æ®µï¼š{FAULT_START_TIME} ~ {FAULT_END_TIME}\")\n",
    "print(f\"   åˆ†æçš„SLSé¡¹ç›®ï¼š{PROJECT_NAME}\")\n",
    "print(f\"   å‘ç°é”™è¯¯spanæ•°é‡ï¼š{len(root_cause_span_ids) if 'root_cause_span_ids' in locals() else 0}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ æ ¹å› å‘ç°ï¼š\")\n",
    "\n",
    "# åˆå§‹åŒ–å…¨å±€å˜é‡ï¼ˆå¦‚æœå°šæœªå®šä¹‰ï¼‰\n",
    "if 'get_patterns_result' not in globals():\n",
    "    get_patterns_result = None\n",
    "if 'diff_patterns_result' not in globals():\n",
    "    diff_patterns_result = None\n",
    "\n",
    "# ä»å·²æœ‰çš„åˆ†æç»“æœä¸­æå–TARGET_SERVICE\n",
    "TARGET_SERVICE = \"unknown\"\n",
    "error_span_evidence = False\n",
    "pattern_evidence = False\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯spanè¯æ®\n",
    "if 'root_cause_span_ids' in locals() and root_cause_span_ids:\n",
    "    error_span_evidence = True\n",
    "    print(f\"   âœ… å·²æ‰¾åˆ° {len(root_cause_span_ids)} ä¸ªé”™è¯¯span\")\n",
    "else:\n",
    "    print(f\"   âŒ æœªæ‰¾åˆ°é”™è¯¯span\")\n",
    "\n",
    "# ä»è¿è¡Œæ—¶æ”¶é›†çš„è¯æ®ä¸­åŠ¨æ€æå–TARGET_SERVICE\n",
    "def parse_service_from_evidence():\n",
    "    \"\"\"ä»get_patternså’Œdiff_patternsçš„å®é™…è¿è¡Œç»“æœä¸­æå–ç›®æ ‡æœåŠ¡\"\"\"\n",
    "\n",
    "    target_service = \"unknown\"\n",
    "    confidence_score = 0\n",
    "\n",
    "    # 1. è§£æget_patternsç»“æœ\n",
    "    # æ ¼å¼: [[\"serviceName=product-catalog\",\"serviceName=frontend-proxy\",\"serviceName=frontend\"],[276,11,2],null,null]\n",
    "    if 'get_patterns_result' in globals() and get_patterns_result:\n",
    "        try:\n",
    "            # Parse the string format from SLS: [[\"serviceName=cart\",\"serviceName=frontend-proxy\"],[139,1],null,null]\n",
    "            if isinstance(get_patterns_result, str):\n",
    "                # Replace 'null' with 'None' for Python parsing\n",
    "                data_str = get_patterns_result.replace('null', 'None')\n",
    "                result = eval(data_str)  # Safely parse the array\n",
    "            else:\n",
    "                result = get_patterns_result\n",
    "\n",
    "            if len(result) >= 2 and isinstance(result[0], list) and isinstance(result[1], list):\n",
    "                service_patterns = result[0]  # æœåŠ¡åæ¨¡å¼\n",
    "                service_counts = result[1]    # å¯¹åº”çš„è®¡æ•°\n",
    "\n",
    "                # æå–æœåŠ¡åå¹¶æ‰¾å‡ºè®¡æ•°æœ€é«˜çš„\n",
    "                max_count = 0\n",
    "                for i, pattern in enumerate(service_patterns):\n",
    "                    if i < len(service_counts):\n",
    "                        count = service_counts[i]\n",
    "                        # ä» \"serviceName=product-catalog\" ä¸­æå–æœåŠ¡å\n",
    "                        if \"serviceName=\" in pattern:\n",
    "                            service = pattern.split(\"serviceName=\")[1].strip('\"\\'')\n",
    "                            if count > max_count:\n",
    "                                max_count = count\n",
    "                                target_service = service\n",
    "                                confidence_score = max_count\n",
    "                                print(f\"   âœ… get_patternså‘ç°ä¸»è¦é”™è¯¯æœåŠ¡: {service} (é”™è¯¯æ•°: {count})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ get_patternsç»“æœè§£æå¤±è´¥: {e}\")\n",
    "\n",
    "    # 2. è§£ædiff_patternsç»“æœè¿›è¡ŒéªŒè¯\n",
    "    # æ ¼å¼: [[\"\\\"serviceName\\\"='product-catalog'\"],[276],[2684],[0.955...]...]\n",
    "    if 'diff_patterns_result' in globals() and diff_patterns_result:\n",
    "        try:\n",
    "            # Parse the string format from SLS: [[\"\\\"serviceName\\\"='cart'\"],[139],[0]...]\n",
    "            if isinstance(diff_patterns_result, str):\n",
    "                # Replace 'null' with 'None' for Python parsing\n",
    "                data_str = diff_patterns_result.replace('null', 'None')\n",
    "                result = eval(data_str)  # Safely parse the array\n",
    "            else:\n",
    "                result = diff_patterns_result\n",
    "\n",
    "            if len(result) >= 1 and isinstance(result[0], list):\n",
    "                anomaly_patterns = result[0]  # å¼‚å¸¸æ¨¡å¼\n",
    "\n",
    "                # ä»å¼‚å¸¸æ¨¡å¼ä¸­æå–æœåŠ¡å\n",
    "                for pattern in anomaly_patterns:\n",
    "                    if \"serviceName\" in pattern and \"=\" in pattern:\n",
    "                        # ä» \"\\\"serviceName\\\"='product-catalog'\" ä¸­æå–æœåŠ¡å\n",
    "                        service = pattern.split(\"='\")[1].strip(\"'\\\"\")\n",
    "                        print(f\"   âœ… diff_patternsç¡®è®¤å¼‚å¸¸æœåŠ¡: {service}\")\n",
    "\n",
    "                        # å¦‚æœget_patternsä¹Ÿæ‰¾åˆ°äº†åŒæ ·çš„æœåŠ¡ï¼Œå¢åŠ ç½®ä¿¡åº¦\n",
    "                        if service == target_service:\n",
    "                            print(f\"   âœ… å¤šé‡è¯æ®ç¡®è®¤: {service} æ˜¯ä¸»è¦æ ¹å› æœåŠ¡\")\n",
    "                            return target_service, True  # é«˜ç½®ä¿¡åº¦\n",
    "                        elif target_service == \"unknown\":\n",
    "                            # å¦‚æœget_patternsæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨diff_patternsçš„ç»“æœ\n",
    "                            target_service = service\n",
    "                            return target_service, True\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ diff_patternsç»“æœè§£æå¤±è´¥: {e}\")\n",
    "\n",
    "    # 3. è¿”å›ç»“æœ\n",
    "    if target_service != \"unknown\":\n",
    "        return target_service, True\n",
    "    else:\n",
    "        print(f\"   âŒ æ— æ³•ä»è¿è¡Œæ—¶è¯æ®ä¸­æå–æ˜ç¡®çš„ç›®æ ‡æœåŠ¡\")\n",
    "        return \"unknown\", False\n",
    "\n",
    "# è§£æè¿è¡Œæ—¶è¯æ®\n",
    "if error_span_evidence:\n",
    "    TARGET_SERVICE, pattern_evidence = parse_service_from_evidence()\n",
    "\n",
    "    if pattern_evidence:\n",
    "        print(f\"   âœ… æ ¹æ®è¿è¡Œæ—¶è¯æ®ç¡®å®šç›®æ ‡æœåŠ¡: {TARGET_SERVICE}\")\n",
    "    else:\n",
    "        print(f\"   âŒ æ— è¶³å¤Ÿçš„æ¨¡å¼åˆ†æè¯æ®\")\n",
    "else:\n",
    "    print(f\"   âŒ æ— è¶³å¤Ÿçš„æ¨¡å¼åˆ†æè¯æ®\")\n",
    "    TARGET_SERVICE = \"unknown\"\n",
    "    pattern_evidence = False\n",
    "\n",
    "print(f\"\\nğŸ† æ ¹å› å€™é€‰ï¼š\")\n",
    "\n",
    "# åŸºäºevidenceçš„è¯„ä¼°\n",
    "evidence = error_span_evidence and pattern_evidence\n",
    "\n",
    "if evidence:\n",
    "    root_cause_candidate = f\"{TARGET_SERVICE}\"\n",
    "    confidence = \"é«˜\"\n",
    "\n",
    "    print(f\"   ğŸ¯ {root_cause_candidate}\")\n",
    "    print(f\"   ğŸ“ˆ ç½®ä¿¡åº¦ï¼š{confidence}\")\n",
    "    print(f\"   âœ… è¯æ®ï¼šTRUEï¼ˆå·²æ£€æµ‹åˆ°å¼‚å¸¸ï¼‰\")\n",
    "    print(f\"   ğŸ“ æ”¯æŒè¯æ®ï¼š\")\n",
    "    print(f\"      - å‘ç° {len(root_cause_span_ids)} ä¸ªé”™è¯¯span\")\n",
    "    print(f\"      - diff_patternsåˆ†æè¡¨æ˜ {TARGET_SERVICE} æœåŠ¡å¼‚å¸¸\")\n",
    "    print(f\"      - æ—¥å¿—æ¨¡å¼åˆ†æéªŒè¯äº†æœåŠ¡é—®é¢˜\")\n",
    "    print(f\"      - é”™è¯¯ç‰¹å¾åˆ†æç¡®è®¤äº†æ ¹å› ä½ç½®\")\n",
    "\n",
    "elif error_span_evidence:\n",
    "    root_cause_candidate = \"unknown\"\n",
    "    confidence = \"ä¸­\"\n",
    "\n",
    "    print(f\"   ğŸ¯ {root_cause_candidate}\")\n",
    "    print(f\"   ğŸ“ˆ ç½®ä¿¡åº¦ï¼š{confidence}\")\n",
    "    print(f\"   âŒ è¯æ®ï¼šFALSEï¼ˆæ¨¡å¼ä¸å¤Ÿæ˜ç¡®ï¼‰\")\n",
    "    print(f\"   ğŸ“ æ”¯æŒè¯æ®ï¼š\")\n",
    "    print(f\"      - å‘ç° {len(root_cause_span_ids)} ä¸ªé”™è¯¯span\")\n",
    "    print(f\"      - ä½†æ¨¡å¼åˆ†æç»“æœä¸å¤Ÿæ˜ç¡®\")\n",
    "\n",
    "else:\n",
    "    root_cause_candidate = \"unknown\"\n",
    "    confidence = \"ä½\"\n",
    "\n",
    "    print(f\"   ğŸ¯ {root_cause_candidate}\")\n",
    "    print(f\"   ğŸ“ˆ ç½®ä¿¡åº¦ï¼š{confidence}\")\n",
    "    print(f\"   âŒ è¯æ®ï¼šFALSEï¼ˆè¯æ®ä¸è¶³ï¼‰\")\n",
    "    print(f\"   ğŸ“ æ”¯æŒè¯æ®ï¼š\")\n",
    "    print(f\"      - é”™è¯¯spanæˆ–æ¨¡å¼åˆ†ææ•°æ®æœ‰é™\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ å»ºè®®ï¼š\")\n",
    "if evidence:\n",
    "    print(f\"   - æ£€æŸ¥ {TARGET_SERVICE} æœåŠ¡çš„å¥åº·çŠ¶æ€\")\n",
    "    print(f\"   - æŸ¥çœ‹ {TARGET_SERVICE} çš„é”™è¯¯æ—¥å¿—å’Œå¼‚å¸¸\")\n",
    "    print(f\"   - éªŒè¯ {TARGET_SERVICE} çš„éƒ¨ç½²å’Œé…ç½®\")\n",
    "    print(f\"   - è€ƒè™‘é‡å¯æˆ–ä¿®å¤ {TARGET_SERVICE} æœåŠ¡\")\n",
    "elif confidence == \"ä¸­\":\n",
    "    print(f\"   - è¿›ä¸€æ­¥åˆ†æé”™è¯¯spançš„åˆ†å¸ƒæ¨¡å¼\")\n",
    "    print(f\"   - æ£€æŸ¥å¤šä¸ªå¯ç–‘æœåŠ¡çš„çŠ¶æ€\")\n",
    "    print(f\"   - æ‰©å¤§æ—¶é—´èŒƒå›´è¿›è¡Œåˆ†æ\")\n",
    "else:\n",
    "    print(f\"   - è°ƒæ•´åˆ†æå‚æ•°ï¼ˆæ—¶é—´èŒƒå›´ç­‰ï¼‰\")\n",
    "    print(f\"   - æ ¸æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´\")\n",
    "    print(f\"   - è€ƒè™‘å…¶ä»–åˆ†ææ–¹æ³•\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ¯ æœ€ç»ˆç­”å¤ï¼š{root_cause_candidate}\")\n",
    "print(f\"ğŸ“ˆ ç½®ä¿¡åº¦ï¼š{confidence}\")\n",
    "print(f\"ğŸ” è¯æ®ï¼š{'TRUE' if evidence else 'FALSE'}\")\n",
    "print(f\"\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
